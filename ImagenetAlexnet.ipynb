{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSKEDfh2FXHG",
    "outputId": "e042e284-93d5-4c68-b8b6-49f9d8f454e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: cuda\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "import shutil\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as func\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"GPU: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4KmsmBf1Ew9T",
    "outputId": "c6354507-50e7-48b9-c0a5-b43b6be0b073"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "l3h5jcPFFWua"
   },
   "outputs": [],
   "source": [
    "# Path to the folder containing the images in Google Drive\n",
    "folder_path = '/content/drive/MyDrive/ImageNet'\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a79O9nx-FYi3",
    "outputId": "c33e0e3e-7699-4d2b-d0b3-bec783ee3031"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 4418\n",
       "    Root location: /content/drive/MyDrive/ImageNet\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(227, 227), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = ImageFolder(root=folder_path, transform=transform)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "aMMYerm1FaAb"
   },
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class ImageNetDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.octmnist = dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.octmnist[index]\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.octmnist)\n",
    "\n",
    "dataset = ImageNetDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "utRZf_ueFbgt"
   },
   "outputs": [],
   "source": [
    "data_size = len(dataset)\n",
    "train_size = int(0.7 * data_size)\n",
    "val_size = int(0.15 * data_size)\n",
    "test_size = data_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVBVu9IKFd2C",
    "outputId": "da1f09e3-20e6-4084-8cc2-99d7fcb5bcbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3092, 664, 662)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Z4ZhesllFd9Y"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XZ4t9dkqFhn0"
   },
   "outputs": [],
   "source": [
    "# Implementing AlexNet\n",
    "class ImageNetCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # [227x227x3] INPUT\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=(11, 11), stride=4, padding=0)  # [55x55x96] CONV1: 96 11x11 filters at stride 4, pad 0\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3), stride = 2) # [27x27x96] MAX POOL1: 3x3 filters at stride 2\n",
    "        self.norm1 = nn.BatchNorm2d(96)  # [27x27x96] NORM1: Normalization layer\n",
    "\n",
    "        self.conv2 = nn.Conv2d(96, 256, kernel_size=(5, 5), stride=1, padding=2) # [27x27x256] CONV2: 256 5x5 filters at stride 1, pad 2\n",
    "        self.drop1 = nn.Dropout(0.3)\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(3, 3), stride = 2) # [13x13x256] MAX POOL2: 3x3 filters at stride 2\n",
    "        self.norm2 = nn.BatchNorm2d(256) # [13x13x256] NORM2: Normalization layer\n",
    "\n",
    "        self.conv3 = nn.Conv2d(256, 384, kernel_size=(3, 3), stride=1, padding=1)  # [13x13x384] CONV3: 384 3x3 filters at stride 1, pad 1\n",
    "        self.norm3 = nn.BatchNorm2d(384)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(384, 384, kernel_size=(3, 3), stride=1, padding=1)  # [13x13x384] CONV4: 384 3x3 filters at stride 1, pad 1\n",
    "        self.norm4 = nn.BatchNorm2d(384),\n",
    "\n",
    "        self.conv5 = nn.Conv2d(384, 256, kernel_size=(3, 3), stride=1, padding=1)  # [13x13x256] CONV5: 256 3x3 filters at stride 1, pad 1\n",
    "        self.norm5 = nn.BatchNorm2d(256),\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(3, 3), stride = 2)  # [6x6x256] MAX POOL3: 3x3 filters at stride 2\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        self.drop2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc6 = nn.Linear(9216, 4096)      # [4096] FC6: 4096 neurons\n",
    "        self.fc7 = nn.Linear(4096, 4096)      # [4096] FC7: 4096 neurons\n",
    "        self.fc8 = nn.Linear(4096, 10)        # [1000] FC8: 1000 neurons (class scores)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu(self.conv1(x))) # self.norm1(\n",
    "        #x = self.drop1(x)\n",
    "\n",
    "        x = self.pool2(self.relu(self.conv2(x))) # self.norm2(\n",
    "\n",
    "        x = self.relu(self.conv3(x))\n",
    "        #x = self.drop2(x)\n",
    "\n",
    "        x = self.relu(self.conv4(x))\n",
    "        #x = self.drop2(x)\n",
    "\n",
    "        x = self.pool3(self.relu(self.conv5(x))) # self.norm5(\n",
    "\n",
    "        x = self.flat(x)\n",
    "        #x = self.drop2(x)\n",
    "\n",
    "        x = self.relu(self.fc6(x))\n",
    "        #x = self.drop2(x)\n",
    "\n",
    "        x = self.relu(self.fc7(x))\n",
    "        x = self.fc8(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DLE4JXfZV7K7"
   },
   "outputs": [],
   "source": [
    "def val_model(model, loss_fn):\n",
    "    val_acc = 0\n",
    "    count = 0\n",
    "    val_loss = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        y_pred = model(inputs)\n",
    "\n",
    "        pred_proba = nn.Softmax(dim=1)(y_pred)\n",
    "        prob_index = torch.argmax(pred_proba, dim=1)\n",
    "\n",
    "        prob_index = prob_index.float()\n",
    "\n",
    "        loss = loss_fn(pred_proba, labels.long())\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        val_acc += (prob_index == labels).float().sum()\n",
    "        count += len(labels)\n",
    "\n",
    "    val_acc /= count\n",
    "    val_loss = round(sum(val_loss)/(len(test_loader)*batch_size), 4)\n",
    "\n",
    "    return round(val_acc.item(), 4) * 100, val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ywLrwJKrFkrl"
   },
   "outputs": [],
   "source": [
    "def train_model_imagenet(model, optimizer, loss_fn, n_epochs=50, early_stopping = False, plot_metrics = False):\n",
    "\n",
    "  for epoch in range(n_epochs):\n",
    "\n",
    "      train_loss = []\n",
    "      len_labels = 0\n",
    "      correct_train_pred = 0\n",
    "      print(\"Epoch started\")\n",
    "      for inputs, labels in train_loader:\n",
    "          inputs = inputs.cuda()\n",
    "          labels = labels.cuda()\n",
    "\n",
    "          y_pred = model(inputs)\n",
    "\n",
    "          pred_proba = nn.Softmax(dim=1)(y_pred)\n",
    "          prob_index = torch.argmax(pred_proba, dim=1)\n",
    "\n",
    "          prob_index = prob_index.float()\n",
    "\n",
    "          loss = loss_fn(pred_proba, labels.long())  # Convert labels to long type\n",
    "          train_loss.append(loss.item())\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          correct_train_pred += (prob_index == labels.data).sum().item()\n",
    "          len_labels += len(labels)\n",
    "\n",
    "      train_acc = round((correct_train_pred / len_labels) * 100, 4)\n",
    "      train_loss = round(sum(train_loss)/(len(test_loader) * batch_size), 4)\n",
    "\n",
    "      val_acc, val_loss = val_model(model, loss_fn)\n",
    "\n",
    "      print(f'epoch {epoch + 1}, training accuracy: {train_acc}, training loss: {train_loss}, Validation Accuracy: {val_acc}, Validation loss: {val_loss}')\n",
    "\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwS3V44Becyp",
    "outputId": "d1d196f4-ac09-48e1-a139-b52e6865f2fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch started\n"
     ]
    }
   ],
   "source": [
    "# Learning rate 1e-2\n",
    "# momentum 0.9\n",
    "# manually when val accuracy plateaus • L2 weight decay 5e-4\n",
    "\n",
    "imagenet_model = ImageNetCNN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(imagenet_model.parameters(), lr=0.01, momentum=0.9, weight_decay = 0.0005)\n",
    "n_epochs = 20\n",
    "\n",
    "imagenet_model = train_model_imagenet(imagenet_model, optimizer, loss_fn, n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkzLfQtpfzSp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
